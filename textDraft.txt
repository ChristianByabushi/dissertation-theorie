 
   
   
   
  \section{ Thinking in Machine Learning}  
  Machine Learning comprises a collection of methods and techniques designed to autonomously identify patterns within data. Subsequently, these discovered patterns are leveraged for tasks such as predicting future data points or facilitating decision-taking in uncertain scenarios. 
  
  In contrast to conventional programming, where applications are crafted with algorithms tailored to solve particular problems or accomplish specific tasks, ML algorithms take a different approach. They build models that possess the ability to learn independently from input data, accumulate experience over time, and actively contribute to the decision-making process of computers   \cite{anwar2019machine}.
    
  Nowadays ML algorithms are utilized in many domains of life. In automotive industry for example, they are integrated in drive-systems to treat data got from sensors, cameras for making autonomous vehicles. In huge companies like Amazon they are used in demand-forecasting by ensuring that popular items are well-stocked, reducing the chances of running out of stock or overstocking; they are also used  to suggest products that customers are likely to be interested in \cite{herbrich2017machine}. Besides, they are used in healthcare systems where they play a significant role since they are able to identify patterns in medical images to detect diseases like cancer; even tailoring treatment plans to individual patients based on their medical history, genetic makeup as well as skin features. \\
 
  Furthermore, reaching the stage where the ML model is ready to make predictions involves a structured sequence of steps that should be followed \cite{mlwithpython}:\\
   
   \textbf{Firstly, the definition of the object and specification} :
   which includes specifying the problem the model aims to solve or the task it should perform. At this stage, all details found serve as project's guiding principles.
      
   \textbf{Secondly, the preparation and exploration} : At this step, ML designer team collects, prepares, examines the data that will be used to train and test the machine learning model. Indeed, the data preparation process encompasses tasks like cleaning, restructuring, formatting, 
   while  data exploration involves using visualization techniques to gain valuable insights from the data that is helpful in outlier detection, trend and clusters identification \cite{unwin2020data}.
      
  \textbf{ Thirdly, the model building} : This step leads to the construction of the model by selecting the most suitable algorithms and techniques for the specific task. Actually, the model ought to be built by using the prepared data.    
  	
 \textbf{ Fourthly, the implementation} : Once the model is constructed, it needs to be seamlessly integrated into the application or system where it will be put into use.  This step involves writing the necessary code and software components to make the model operational, capable of predictions, or generating insights. 
   
  \textbf{ Fifthly, the testing} : At this stage, the model's performance is assessed using a separate dataset that was not used during training. It is important to ensure that the model can consistently make accurate predictions and to identify and address any potentials issues of shortcomings.\\
   
  \textbf{ Finally, the deployment} : Once the model is tested, then it is deployed in production environment so that it may be accessible to users or systems where it can provide predictions or insights based on new data.
  	
 \section{Categorization of ML}
  As seen early, we have seen 3 main types of ML learning such as : a) Supervised model, b) Unsupervised model and c) reinforcement models. In the following lines, we dive into the details. 
 \subsection{Supervised models}  
	Supervised machine learning algorithms utilize input data, which includes both input features and the corresponding output labels, to train models and learn to make predictions. To facilitate understanding and communication, data scientists often use specific terms: 
	\begin{enumerate}[label=\alph*)]
	\item \textbf{Row}: \textit{A row} refers to each line or entry in the dataset, typically represented horizontally. Each row contains a set of input features along with their corresponding output label. 
	\item \textbf{Features} :  \textit{Features} are the characteristic or attributes of the data. They are usually represented in columns within the dataset. Each column corresponds to a specific feature, and these features collectively describe the input data. 

	\item \textbf{Feature Vector} : \textit{A feature} is a representation of a single data point, typically a row, in the dataset. It consists of all the values in that row except for the label value, which is called the \textit{\textbf{target}}. Essentially, the feature vector comprises the input features that the model uses to make predictions. 
	\item \textbf{Labels/targets vector, (Y)} : \textit{Labels}, represent the feature column which contains the output.  
	\item \textbf{Features matrix, (X)} : \textit{Features matrix} represent  all the dataset except the the column which contains the labels
	\end{enumerate} 
Besides, the Supervised models are used to perform specific many tasks:

\textbf{Classification tasks}: These tasks involve categorizing input data into predefined classes or labels. The model learns to assign the correct category to new data based on patterns learned during training. Examples include : Spam detection for classifying whether a message is a spam or not; Sentiment analysis for determining the social media posts text which can be positive, negative or neutral; image classification for identifying objects or categories in images.

\textbf{Regression tasks}  : Regression tasks focus on prediction continuous numeric values based on input features. These models learn to make predictions such as house prices, stock prices or temperature forecasts.

\textbf{Object Detection and Recognition} :  Models can be trained to identify and locate objects within images or videos. This is crucial for applications like autonomous vehicles and surveillance systems.
\textbf{Natural Language Processing (NLP)}  : NLP models are utilized in process of translating text form one language to another and identifying entities (e.g, names, locations) in text. 

\textbf{Time series Analysis} : Time series models predict future values based on historical time-order data, with applications in in finance, weather forecasting, and demand prediction.

\textbf{Speech Recognition} : Models convert spoken language into text, enabling voice assistants and transcription services.

\textbf{Deep learning} : Deep learning are particularly powerful in tasks that involve large datasets, complex patterns, and unstructured data like images,text,and audio. They have the ability of automatically learning hierarchical representations from data for performing tasks.
\\
Actually, all these tasks involves using a specific algorithm which can fit either the problem or the data. The common algorithms used in supervised model category include : The Linear Models, Logistic Regression, Tree-Based Models, Naive Bayes, Support Vector Machines (SVM), Neural Networks, K-Nearest Neighbors (K-NN), Ensemble Methods, Tree-Based Models including Decision Trees, Random Forest, Gradient Boosting Trees and many others. 
\\

Since data, scenarios and problems are clues that specify the kind of classification Models to use, the following table gives the overview of the type of algorithm to use when the types of data are qualitative: 	


